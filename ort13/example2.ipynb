{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: extensions\n",
    "More complicated inputs. .\n",
    "1. Here, we want to pass in an array to the inference.\n",
    "2. Notice that the warmup example fixes the lengths of the array that the onnx model expects.\n",
    "3. check out the netron visualization of the model.\n",
    "\n",
    "In this example, we take an array `x`, and then take the `max` of the entries in `x`.\n",
    "denote the max by `k`, then we return `m*k + c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = \"example2.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SampleNet, self).__init__()\n",
    "        self.m = 2\n",
    "        self.c = 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.m * torch.max(x) + self.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note\n",
    "if we replace the `torch.max` above by `np.max` then we will get errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet()"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SampleNet()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warmup stage. \n",
    "x = torch.LongTensor([1, 2, 3, 4])\n",
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "model,\n",
    "x,\n",
    "onnx_model,\n",
    "opset_version=11,\n",
    "do_constant_folding=True,\n",
    "input_names=['input'],\n",
    "output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping http://localhost:8081\n",
      "Serving 'example2.onnx' at http://localhost:8081\n"
     ]
    }
   ],
   "source": [
    "# uncomment to install netron.\n",
    "#!pip install netron\n",
    "import netron\n",
    "netron.start(onnx_model, port=8081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "sess = ort.InferenceSession(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(45, dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "# check out the signature of sess.run - it has to have the output, then something like a feed_dict.\n",
    "\n",
    "# either pass the feed dict directly.\n",
    "# passing an array of any other size will result in an error.\n",
    "outs = sess.run(['output'],\n",
    "                       {\n",
    "                         'input': np.array([11, 20, 22, 12], dtype=np.int64)  \n",
    "                       })\n",
    "\n",
    "print(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
