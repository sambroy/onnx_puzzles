{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: `argmax` -- working solution.\n",
    "\n",
    "As in `Example 2`, we\n",
    "1. pass in an array to the inference.\n",
    "2. Notice that the warmup example fixes the lengths of the array that the onnx model expects.\n",
    "3. check out the netron visualization of the model.\n",
    "\n",
    "In this example, we take an array `x`, and then take the `argmax` of the entries in `x`.\n",
    "denote this index by `k`, then we return `m*k + c`.\n",
    "\n",
    "Here, we will try a workaround: \n",
    "1. Compute the `max` of the array `x`. As we saw in `Example 2`, `onnxruntime` has `max` implemented\n",
    "(`ReduceMax`).\n",
    "2. Compute a `mask` consisting of the entries in the array that are `geq` than this `max`.\n",
    "Note that this `mask` is an array of `0`s and `1`s. If the original array has a unique maximum, then \n",
    "this array will have exactly one `1`. \n",
    "3. If the nonzero array be called `nz`, then pick up the `argmax` as `nz[0][0]`. Note that the array `nz` has `size(1, k)` where `k` is the number of appearances of the `max` in the array.\n",
    "\n",
    "**Note**:\n",
    "1. If the `max` appears in the array `x` multiple times, then we pick up the _smallest_ index at which \n",
    "the `max` appears. \n",
    "If you want to pick up the _last_ appearance of the `max` in the array `x`, then that is simple too:\n",
    "use `nz[-1][0]` instead of `nz[0][0]`.\n",
    "2. Also, note that we use `torch.nonzero(mask, as_tuple=False)`; this is because of [this issue](https://github.com/pytorch/pytorch/issues/32994#issuecomment-629810935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = \"example4.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SampleNet, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b = torch.max(x)\n",
    "        mask = x.ge(b).type(torch.int64)\n",
    "        nz = torch.nonzero(mask, as_tuple=False)\n",
    "        return nz[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SampleNet()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the warmup stage\n",
    "x = torch.LongTensor([1, 2, 3, 4])\n",
    "out = model(x)  # the argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "model,\n",
    "x,\n",
    "onnx_model,\n",
    "opset_version=11,\n",
    "do_constant_folding=True,\n",
    "input_names=['input'],\n",
    "output_names=['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'example4.onnx' at http://localhost:8083\n"
     ]
    }
   ],
   "source": [
    "# uncomment to install netron.\n",
    "#!pip install netron\n",
    "import netron\n",
    "netron.start(onnx_model, port=8083)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.enable_profiling = True\n",
    "sess = ort.InferenceSession(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(2, dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "# check out the signature of sess.run - it has to have the output, then something like a feed_dict.\n",
    "\n",
    "# either pass the feed dict directly.\n",
    "# passing an array of any other size will result in an error.\n",
    "outs = sess.run(['output'],\n",
    "                       {\n",
    "                         'input': np.array([11, 20, 22, 12], dtype=np.int64)  \n",
    "                       })\n",
    "\n",
    "print(outs)  # should be 2, since array[2] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
